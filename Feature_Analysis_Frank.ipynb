{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b276bc3",
   "metadata": {},
   "source": [
    "# Feature Analysis\n",
    "### Cursory exploration of model performance when comparing the 33 mfcc features, the echonest audio features, and both combined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3801e613",
   "metadata": {},
   "source": [
    "## Setup\n",
    "* Library Imports\n",
    "* Data set and subset loading\n",
    "* Function definitions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0732505a-ea15-439f-9189-9e01d97e6ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------- Library Imports --------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load dataset using utils.load()\n",
    "# Non-standard library in root directory\n",
    "import utils\n",
    "\n",
    "\n",
    "# -------------------------- Data Loading --------------------------\n",
    "\n",
    "tracks = utils.load('data/fma_metadata/tracks.csv')\n",
    "genres = utils.load('data/fma_metadata/genres.csv')\n",
    "features = utils.load('data/fma_metadata/features.csv')\n",
    "echonest = utils.load('data/fma_metadata/echonest.csv')\n",
    "\n",
    "# Inner join all tracks present in both the Echonest and Features data sets.\n",
    "features_all = features.join(echonest, how='inner').sort_index(axis=1)\n",
    "\n",
    "# Extract subsets\n",
    "small = tracks['set', 'subset'] <= 'small'\n",
    "medium = tracks['set', 'subset'] <= 'medium'\n",
    "\n",
    "\n",
    "# -------------------------- Function Definitions --------------------------\n",
    "\n",
    "def preprocess_data(X, y, test_size_ratio=0.2):\n",
    "    try:\n",
    "        # Perform Train-Test Split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size_ratio, stratify=y, random_state=42)\n",
    "        \n",
    "        print(f\"{y_train.size} training examples, {y_test.size} testing examples\")\n",
    "        print(f\"{X_train.shape[1]} features, {np.unique(y_train).size} classes\")\n",
    "        \n",
    "        # Scale Features to Improve Convergence\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # Handle Missing Values\n",
    "        X_train = np.nan_to_num(X_train)\n",
    "        X_test = np.nan_to_num(X_test)\n",
    "        \n",
    "        # Apply PCA if needed (e.g., reducing to 50 components)\n",
    "        if X_train.shape[1] > 200:\n",
    "            print(\"Applying PCA to reduce features...\")\n",
    "            pca = PCA(n_components=50)\n",
    "            X_train = pca.fit_transform(X_train)\n",
    "            X_test = pca.transform(X_test)\n",
    "\n",
    "        # Return processed test/train sets\n",
    "        return (X_train, X_test, y_train, y_test)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f'error: {e}')\n",
    "    \n",
    "def train_models(X_train, y_train, X_test):\n",
    "    try:\n",
    "        # Logistic Regression \n",
    "        lr_model = LogisticRegression(max_iter=2000, solver='saga', random_state=42)\n",
    "        lr_model.fit(X_train, y_train)\n",
    "        y_pred_lr = lr_model.predict(X_test)\n",
    "        \n",
    "        # Support Vector Machine (SVM)\n",
    "        svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
    "        svm_model.fit(X_train, y_train)\n",
    "        y_pred_svm = svm_model.predict(X_test)\n",
    "        \n",
    "        # K-Nearest Neighbors (KNN)\n",
    "        knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "        knn_model.fit(X_train, y_train)\n",
    "        y_pred_knn = knn_model.predict(X_test)\n",
    "        \n",
    "        # Multilayer Perceptron\n",
    "        mlp_model = MLPClassifier(hidden_layer_sizes=(100,)*10, max_iter=2000)\n",
    "        mlp_model.fit(X_train, y_train)\n",
    "        y_pred_mlp = mlp_model.predict(X_test)\n",
    "\n",
    "        return (y_pred_lr, y_pred_svm, y_pred_knn, y_pred_mlp)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'error: {e}')\n",
    "    \n",
    "# Function to evaluate models\n",
    "def evaluate_model(name, y_test, y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print(f\"\\n{name} Performance:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263bcf99",
   "metadata": {},
   "source": [
    "# Experiment 1 - MFCC features\n",
    "This experiment simply serves as a basis for comparison and simply regenerates the results of the original researchers.  \n",
    "Here we are using the small data set, to keep our data set size relatively similar between experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a81fb89a-9783-4f30-94d0-44f2c0c47364",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400 training examples, 1600 testing examples\n",
      "140 features, 8 classes\n",
      "\n",
      "Logistic Regression (LR) Performance:\n",
      "Accuracy: 0.5081\n",
      "F1-score: 0.4984\n",
      "Confusion Matrix:\n",
      " [[ 99  14   1  38  12  12  11  13]\n",
      " [ 22  52  14  14  39  18  19  22]\n",
      " [  3   7 131   1  17  16  16   9]\n",
      " [ 25   9   5 128   4  12  12   5]\n",
      " [ 13  22  15   3 110  14   9  14]\n",
      " [ 10  13  18  17  10 116   8   8]\n",
      " [ 20  22  21  22  17  16  51  31]\n",
      " [  9   8  12   7   8  13  17 126]]\n",
      "\n",
      "Support Vector Machine (SVM) Performance:\n",
      "Accuracy: 0.5713\n",
      "F1-score: 0.5691\n",
      "Confusion Matrix:\n",
      " [[113  17   1  26  12   7  17   7]\n",
      " [ 23  89   9   9  36   4  20  10]\n",
      " [  3   8 140   1  16  11  15   6]\n",
      " [ 32   9   3 131   5   7  10   3]\n",
      " [ 16  23  13   1 123   3  12   9]\n",
      " [ 16   9  16  14   5 123  10   7]\n",
      " [ 18  19  18  22  15   9  68  31]\n",
      " [ 11  14  17   5   6   7  13 127]]\n",
      "\n",
      "K-Nearest Neighbors (KNN) Performance:\n",
      "Accuracy: 0.5012\n",
      "F1-score: 0.4895\n",
      "Confusion Matrix:\n",
      " [[ 86  11  13  45  10  17  14   4]\n",
      " [ 25  48  21  24  35  20  18   9]\n",
      " [  2   3 149   5  11  17   9   4]\n",
      " [ 36   3  13 121   6   9   7   5]\n",
      " [ 19  13  19   9 107  18  10   5]\n",
      " [  4   5  18  21   4 140   8   0]\n",
      " [ 14  20  25  29  16  24  59  13]\n",
      " [  9   8  20   7   7  18  39  92]]\n",
      "\n",
      "Multilayer Perceptron (MLP) Performance:\n",
      "Accuracy: 0.5038\n",
      "F1-score: 0.5028\n",
      "Confusion Matrix:\n",
      " [[ 90  21   6  25  16  19  17   6]\n",
      " [ 21  81  14  12  29  12  18  13]\n",
      " [  4  13 124   3  18  11  21   6]\n",
      " [ 24   9   2 107   6  24  23   5]\n",
      " [ 13  31  14   6 110   6  11   9]\n",
      " [  9   8  17   8   6 128  19   5]\n",
      " [ 18  23  28  17  13  17  57  27]\n",
      " [  5  12  16   5  11   8  34 109]]\n"
     ]
    }
   ],
   "source": [
    "# Extract Features and Labels\n",
    "X = features.loc[small, 'mfcc']  # Using only MFCC features\n",
    "y = tracks.loc[small, ('track', 'genre_top')]  # Extracting genre labels\n",
    "\n",
    "# -------------------------- Data Preprocessing --------------------------\n",
    "X_train, X_test, y_train, y_test = preprocess_data(X, y)\n",
    "\n",
    "# -------------------------- Model Training and Evaluation --------------------------\n",
    "y_pred_lr, y_pred_svm, y_pred_knn, y_pred_mlp = train_models(X_train, y_train, X_test)\n",
    "\n",
    "# -------------------------- Evaluation --------------------------\n",
    "evaluate_model(\"Logistic Regression (LR)\", y_test, y_pred_lr)\n",
    "evaluate_model(\"Support Vector Machine (SVM)\", y_test, y_pred_svm)\n",
    "evaluate_model(\"K-Nearest Neighbors (KNN)\", y_test, y_pred_knn)\n",
    "evaluate_model(\"Multilayer Perceptron (MLP)\", y_test, y_pred_mlp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7ae918",
   "metadata": {},
   "source": [
    "# Experiment 2 - Echonest Audio Features\n",
    "Using the same models as before, we instead train them on the echonest audio features (danceability, energy, etc.).  \n",
    "Here we switched to the medium set, since the available tracks which have echonest data is much smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdb245bb-409d-401f-a441-ddc3d87f1e50",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4224 training examples, 1057 testing examples\n",
      "8 features, 12 classes\n",
      "\n",
      "Logistic Regression (LR) Performance:\n",
      "Accuracy: 0.5904\n",
      "F1-score: 0.3013\n",
      "Confusion Matrix:\n",
      " [[  0   0   1   0   0   0   0   0   0   4   0   4]\n",
      " [  0  24   0   0   6   1   0   0   0   1   0   3]\n",
      " [  0   2 187   0   8   7   0   1   0   0   2  70]\n",
      " [  0   0   0   0   1   0   0   0   0   0   0   2]\n",
      " [  0   8   8   0  15   3   0   0   1   4   4  43]\n",
      " [  0   0  43   0   1  45   0   0   0   1   0  16]\n",
      " [  0   0   5   0   1   0   0   0   0   0   0   5]\n",
      " [  0   0   2   0   3   2   0   1   0   5   0   9]\n",
      " [  0   3   4   0   7   2   0   0   0   2   0  11]\n",
      " [  0   7   1   0   3   0   0   1   0  49   1   2]\n",
      " [  0   1   8   0   7   5   0   0   0   1   5  19]\n",
      " [  0   0  47   0   9   6   0   1   0   5   3 298]]\n",
      "\n",
      "Support Vector Machine (SVM) Performance:\n",
      "Accuracy: 0.6112\n",
      "F1-score: 0.3156\n",
      "Confusion Matrix:\n",
      " [[  0   0   1   0   0   1   0   2   0   2   0   3]\n",
      " [  0  26   1   0   6   0   0   0   0   1   0   1]\n",
      " [  0   2 195   0   8   6   0   0   0   0   0  66]\n",
      " [  0   0   0   0   1   0   0   0   0   0   0   2]\n",
      " [  0   9   5   0  27   3   0   0   0   2   0  40]\n",
      " [  0   0  46   0   1  39   0   0   0   2   0  18]\n",
      " [  0   0   3   0   0   0   0   0   0   0   1   7]\n",
      " [  0   0   2   0   3   1   0   2   0   2   0  12]\n",
      " [  0   3   5   0   8   1   0   0   0   3   0   9]\n",
      " [  0   5   1   0   5   0   0   0   0  51   1   1]\n",
      " [  0   1   9   0   6   3   0   0   0   1   1  25]\n",
      " [  0   0  42   0  12   6   0   2   0   2   0 305]]\n",
      "\n",
      "K-Nearest Neighbors (KNN) Performance:\n",
      "Accuracy: 0.5553\n",
      "F1-score: 0.3024\n",
      "Confusion Matrix:\n",
      " [[  1   0   1   0   0   1   0   2   0   2   0   2]\n",
      " [  0  21   1   0   6   0   0   0   2   2   1   2]\n",
      " [  1   3 182   0  12  21   0   0   0   1   5  52]\n",
      " [  0   0   1   0   1   0   0   0   0   0   0   1]\n",
      " [  2   9   8   1  28   5   0   2   2   4   3  22]\n",
      " [  2   0  43   0   1  44   0   0   1   1   2  12]\n",
      " [  0   0   6   0   1   0   0   0   0   0   1   3]\n",
      " [  3   0   3   0   3   1   0   2   0   2   2   6]\n",
      " [  0   5   7   0   6   1   0   1   2   1   0   6]\n",
      " [  0   8   1   0   8   0   0   1   0  44   0   2]\n",
      " [  1   2  13   0   4   6   0   0   1   1   2  16]\n",
      " [  1   4  55   0  25   9   0   2   1   5   6 261]]\n",
      "\n",
      "Multilayer Perceptron (MLP) Performance:\n",
      "Accuracy: 0.5345\n",
      "F1-score: 0.3555\n",
      "Confusion Matrix:\n",
      " [[  1   0   1   0   0   1   0   3   0   1   0   2]\n",
      " [  0  25   2   0   4   0   0   0   0   2   0   2]\n",
      " [  1   0 172   0  13  30   1   0   2   1   9  48]\n",
      " [  0   0   2   0   1   0   0   0   0   0   0   0]\n",
      " [  2   2   4   0  33   9   0   3   5   0   6  22]\n",
      " [  1   0  28   0   2  55   1   1   2   1   4  11]\n",
      " [  0   0   4   0   1   0   1   0   1   0   2   2]\n",
      " [  1   0   2   0   2   2   2   6   1   2   0   4]\n",
      " [  0   3   5   0   7   2   0   0   5   0   0   7]\n",
      " [  0   8   0   0   4   0   1   1   0  45   0   5]\n",
      " [  1   2  10   0   7   3   0   2   0   0   5  16]\n",
      " [  2   1  57   0  21  16   1   5  15   2  32 217]]\n"
     ]
    }
   ],
   "source": [
    "# Extract Features and Labels\n",
    "X = features_all.loc[medium, ('echonest', 'audio_features')]  # Using only Echonest audio features\n",
    "y = tracks.loc[medium, ('track', 'genre_top')]  # Extracting genre labels\n",
    "X, y = X.align(y, join='inner', axis=0)\n",
    "\n",
    "# -------------------------- Data Preprocessing --------------------------\n",
    "X_train, X_test, y_train, y_test = preprocess_data(X, y)\n",
    "\n",
    "# -------------------------- Model Training and Evaluation --------------------------\n",
    "y_pred_lr, y_pred_svm, y_pred_knn, y_pred_mlp = train_models(X_train, y_train, X_test)\n",
    "\n",
    "# -------------------------- Evaluation --------------------------\n",
    "evaluate_model(\"Logistic Regression (LR)\", y_test, y_pred_lr)\n",
    "evaluate_model(\"Support Vector Machine (SVM)\", y_test, y_pred_svm)\n",
    "evaluate_model(\"K-Nearest Neighbors (KNN)\", y_test, y_pred_knn)\n",
    "evaluate_model(\"Multilayer Perceptron (MLP)\", y_test, y_pred_mlp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cd43a3",
   "metadata": {},
   "source": [
    "## Experiment 3 - MFCC + Echonest Audio Features\n",
    "This experiment combines both feature sets. Note that the total data set size is still the same, we just have an additional 33 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcedd028-08cc-420d-b136-52e54f89fc93",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4224 training examples, 1057 testing examples\n",
      "148 features, 12 classes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Frank\\.conda\\envs\\fma_ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression (LR) Performance:\n",
      "Accuracy: 0.7086\n",
      "F1-score: 0.5405\n",
      "Confusion Matrix:\n",
      " [[  2   0   1   0   0   1   0   0   1   0   0   4]\n",
      " [  0  27   1   1   1   0   0   0   3   0   0   2]\n",
      " [  0   0 204   0   5  25   3   1   7   1   5  26]\n",
      " [  0   0   1   1   0   0   0   0   0   0   0   1]\n",
      " [  0   1   6   1  43   1   0   1   2   1   3  27]\n",
      " [  2   0  27   0   1  60   2   0   1   0   1  12]\n",
      " [  0   0   2   0   0   0   3   0   1   0   1   4]\n",
      " [  1   1   0   0   3   2   0  14   0   0   1   0]\n",
      " [  1   3   5   0   5   0   0   0   9   0   0   6]\n",
      " [  0   1   1   0   2   0   0   0   0  59   0   1]\n",
      " [  1   0   7   0   7   3   0   0   0   0   9  19]\n",
      " [  0   2  22   0   9   8   1   6   1   1   1 318]]\n",
      "\n",
      "Support Vector Machine (SVM) Performance:\n",
      "Accuracy: 0.7493\n",
      "F1-score: 0.5083\n",
      "Confusion Matrix:\n",
      " [[  1   0   2   0   0   0   0   0   0   0   0   6]\n",
      " [  0  30   1   0   1   0   0   0   1   0   0   2]\n",
      " [  0   0 236   0   6   7   0   0   0   0   0  28]\n",
      " [  0   0   0   0   1   0   0   0   0   0   0   2]\n",
      " [  0   0   6   0  49   2   0   0   1   1   0  27]\n",
      " [  0   0  35   0   0  59   0   0   1   0   1  10]\n",
      " [  0   0   2   0   0   0   0   0   0   0   0   9]\n",
      " [  0   0   3   0   2   1   0  13   0   0   0   3]\n",
      " [  0   4   3   0   3   1   0   0   8   0   0  10]\n",
      " [  0   0   3   0   0   0   0   0   0  61   0   0]\n",
      " [  0   0  11   0   7   6   0   0   0   0   3  19]\n",
      " [  0   1  24   0   4   6   0   1   0   1   0 332]]\n",
      "\n",
      "K-Nearest Neighbors (KNN) Performance:\n",
      "Accuracy: 0.7067\n",
      "F1-score: 0.5329\n",
      "Confusion Matrix:\n",
      " [[  6   0   2   0   0   0   0   0   0   0   0   1]\n",
      " [  1  32   0   0   0   1   0   0   0   1   0   0]\n",
      " [  0   1 200   0   8  21   0   2   0   0   0  45]\n",
      " [  0   0   0   0   0   0   0   0   0   1   0   2]\n",
      " [  1   3   3   0  48   3   0   1   3   0   2  22]\n",
      " [  0   0  34   0   0  57   0   1   0   0   0  14]\n",
      " [  0   0   2   0   0   0   1   1   0   0   0   7]\n",
      " [  0   0   1   0   3   1   0  13   0   0   1   3]\n",
      " [  1   5   3   0   2   0   0   0   8   0   3   7]\n",
      " [  0   0   2   0   2   0   0   0   0  60   0   0]\n",
      " [  0   0   7   0   8   8   0   0   0   0   5  18]\n",
      " [  0   1  26   0   3   5   0   5   2   0  10 317]]\n",
      "\n",
      "Multilayer Perceptron (MLP) Performance:\n",
      "Accuracy: 0.6632\n",
      "F1-score: 0.4407\n",
      "Confusion Matrix:\n",
      " [[  1   0   0   0   1   2   0   2   0   0   1   2]\n",
      " [  0  23   2   1   1   0   1   0   5   0   0   2]\n",
      " [  1   0 196   0   3  21   4   2   5   0  16  29]\n",
      " [  0   1   1   0   0   0   0   0   0   0   0   1]\n",
      " [  2   1   5   1  43   0   1   3   5   1   3  21]\n",
      " [  0   0  32   0   1  57   2   1   1   0   8   4]\n",
      " [  0   0   1   0   3   0   1   0   0   0   1   5]\n",
      " [  3   0   1   0   5   1   0  10   2   0   0   0]\n",
      " [  0   4   3   0   1   0   4   0  10   0   2   5]\n",
      " [  0   0   1   0   2   0   0   0   0  61   0   0]\n",
      " [  1   0   9   1   5   7   0   0   0   0   3  20]\n",
      " [  1   1  29   2  10   4   8   6   2   0  10 296]]\n"
     ]
    }
   ],
   "source": [
    "# Extract Features and Labels\n",
    "X = pd.concat([ \n",
    "    features_all.loc[medium, ('echonest', 'audio_features')], # Both Echonest audio features and mfcc\n",
    "    features_all.loc[medium, 'mfcc']\n",
    "    ], axis=1)\n",
    "X.columns = X.columns.astype(str) # Since the feature col names are tuples in features set, but strings in echonest set - we must convert\n",
    "y = tracks.loc[medium, ('track', 'genre_top')]  # Extracting genre labels\n",
    "X, y = X.align(y, join='inner', axis=0)\n",
    "\n",
    "# -------------------------- Data Preprocessing --------------------------\n",
    "X_train, X_test, y_train, y_test = preprocess_data(X, y)\n",
    "\n",
    "# -------------------------- Model Training and Evaluation --------------------------\n",
    "y_pred_lr, y_pred_svm, y_pred_knn, y_pred_mlp = train_models(X_train, y_train, X_test)\n",
    "\n",
    "# -------------------------- Evaluation --------------------------\n",
    "evaluate_model(\"Logistic Regression (LR)\", y_test, y_pred_lr)\n",
    "evaluate_model(\"Support Vector Machine (SVM)\", y_test, y_pred_svm)\n",
    "evaluate_model(\"K-Nearest Neighbors (KNN)\", y_test, y_pred_knn)\n",
    "evaluate_model(\"Multilayer Perceptron (MLP)\", y_test, y_pred_mlp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d239f7-f4dd-4bad-bed8-0b5c388347e2",
   "metadata": {},
   "source": [
    "### Quick script to get the in-order column feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3bdc25d-5dd5-4aee-9682-ffbbd480ec54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: (In order):\n",
      " ['Blues' 'Classical' 'Electronic' 'Experimental' 'Folk' 'Hip-Hop'\n",
      " 'Instrumental' 'International' 'Jazz' 'Old-Time / Historic' 'Pop' 'Rock']\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_mlp)\n",
    " \n",
    "# Print out the columns (class labels)\n",
    "print(\"Labels: (In order):\\n\", np.unique(y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fma_ml)",
   "language": "python",
   "name": "fma_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
